---
title: "Portfolio Optimization using the Performer Model"
subtitle: "Comparing Linear Attention Transformer with Mean-Variance Optimization"
author: "Krishna"
date: "March 17, 2025"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
    number-sections: true
    highlight-style: github
    theme: cosmo
jupyter: python3
---

# Introduction

Portfolio optimization is a critical task in finance that aims to allocate assets in a way that maximizes returns while minimizing risk. Traditional approaches like Mean-Variance Optimization (MVO) have been the cornerstone of modern portfolio theory since Harry Markowitz's seminal work in 1952. However, with the advancement of machine learning and deep learning techniques, new approaches have emerged that can potentially capture more complex patterns and relationships in financial data.

This document explores the application of the Performer Model, a linear attention transformer architecture, to portfolio optimization and compares its performance with traditional Mean-Variance Optimization. The Performer Model offers several advantages, including linear computational complexity and the ability to model complex non-linear relationships in financial time series data.

## Objectives

1. Implement the Performer Model (Linear Attention Transformer) for portfolio optimization
2. Implement traditional Mean-Variance Optimization (MVO)
3. Compare the performance of both approaches using various metrics
4. Analyze the strengths and weaknesses of each approach

## Dataset

We will use historical stock price data from major indices obtained through the Yahoo Finance API. This will allow us to test our models on real-world financial data and evaluate their performance in practical scenarios.

# Theoretical Background

## Mean-Variance Optimization (MVO)

Mean-Variance Optimization is a mathematical framework for assembling a portfolio of assets such that the expected return is maximized for a given level of risk. It is based on the following principles:

1. Portfolio return is the proportion-weighted combination of the constituent assets' returns
2. Portfolio risk (variance) is a function of the correlations between component assets
3. Investors are risk-averse and prefer portfolios with higher expected returns and lower risk

The mathematical formulation of MVO is as follows:

$$
\begin{align}
\text{Maximize } & \mu_p = \sum_{i=1}^{n} w_i \mu_i \\
\text{Subject to } & \sigma_p^2 = \sum_{i=1}^{n} \sum_{j=1}^{n} w_i w_j \sigma_i \sigma_j \rho_{ij} \leq \sigma_{\text{target}}^2 \\
& \sum_{i=1}^{n} w_i = 1 \\
& w_i \geq 0, \forall i \in \{1, 2, \ldots, n\}
\end{align}
$$

where:
- $\mu_p$ is the expected return of the portfolio
- $\mu_i$ is the expected return of asset $i$
- $w_i$ is the weight of asset $i$ in the portfolio
- $\sigma_p^2$ is the variance of the portfolio
- $\sigma_i$ is the standard deviation of asset $i$
- $\rho_{ij}$ is the correlation coefficient between assets $i$ and $j$
- $\sigma_{\text{target}}^2$ is the target variance level

## Performer Model (Linear Attention Transformer)

The Performer Model is a Transformer architecture that uses a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+) to approximate the attention mechanism with linear complexity instead of quadratic complexity. This makes it suitable for processing long sequences of financial data efficiently.

Traditional Transformer attention is computed as:

$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

where $Q$, $K$, and $V$ are the query, key, and value matrices, and $d_k$ is the dimension of the keys.

The Performer replaces this with a linear attention mechanism:

$$\text{LinearAttention}(Q, K, V) = \phi(Q)(\phi(K)^T V)$$

where $\phi$ is a feature map that approximates the softmax kernel. This reduces the computational complexity from $O(n^2)$ to $O(n)$, where $n$ is the sequence length.

For portfolio optimization, the Performer can process historical price sequences and learn complex patterns that may not be captured by traditional statistical methods like MVO.

# Implementation

## Setup and Data Loading

First, let's set up our environment and load the necessary libraries:

```{python}
# Import necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from datetime import datetime, timedelta
from scipy.optimize import minimize
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# Set random seeds for reproducibility
np.random.seed(42)
torch.manual_seed(42)

# Set plotting style
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (12, 8)
```

Now, let's load historical stock data using the Yahoo Finance API:

```{python}
import pandas as pd
import os
import numpy as np
from scipy.optimize import minimize

# Define the list of stocks to include in our portfolio
stocks = ['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'NVDA', 'JPM', 'V', 'JNJ']

# Load data
clean_data_dir = 'c:/Users/krish/OneDrive/Desktop/Research-Portfolio Optimization/data/clean_data'
clean_data_path = os.path.join(clean_data_dir, 'stock_data_clean.csv')
df_clean = pd.read_csv(clean_data_path)

# Select stocks from predefined list with exact "Close" columns
close_columns = [col for col in df_clean.columns if any(stock in col for stock in stocks) and col.endswith('Close')]
returns = df_clean[close_columns].pct_change().dropna()

# Display the first few rows of the returns data
print(returns.head())

```

## Mean-Variance Optimization Implementation

Let's implement the traditional Mean-Variance Optimization approach:

```{python}
def calculate_portfolio_performance(weights, returns):
    """
    Calculate portfolio performance metrics: return, volatility, Sharpe ratio
    """
    # Expected portfolio return
    portfolio_return = np.sum(returns.mean() * weights) * 252  # Annualized
    
    # Expected portfolio volatility
    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))
    
    # Sharpe ratio (assuming risk-free rate of 0 for simplicity)
    sharpe_ratio = portfolio_return / portfolio_volatility
    
    return portfolio_return, portfolio_volatility, sharpe_ratio

def negative_sharpe_ratio(weights, returns):
    """
    Returns the negative Sharpe ratio (for minimization)
    """
    return -calculate_portfolio_performance(weights, returns)[2]

def optimize_portfolio(returns):
    """
    Perform Mean-Variance Optimization to find the optimal portfolio weights
    """
    # Number of assets
    num_assets = len(returns.columns)
    
    # Initial guess (equal weights)
    init_weights = np.array([1.0/num_assets] * num_assets)
    
    # Constraints: weights sum to 1
    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
    
    # Bounds: no short selling (weights between 0 and 1)
    bounds = tuple((0, 1) for asset in range(num_assets))
    
    # Optimize for maximum Sharpe ratio
    result = minimize(negative_sharpe_ratio, init_weights, args=(returns,), 
                      method='SLSQP', bounds=bounds, constraints=constraints)
    
    # Get the optimized weights
    optimal_weights = result['x']
    
    # Calculate performance metrics with optimized weights
    performance = calculate_portfolio_performance(optimal_weights, returns)
    
    return optimal_weights, performance

# Run Mean-Variance Optimization
mvo_weights, mvo_performance = optimize_portfolio(returns)

# Display the results
mvo_results = pd.DataFrame({
    'Asset': returns.columns,
    'Weight': mvo_weights
})

print("Mean-Variance Optimization Results:")
print(f"Expected Annual Return: {mvo_performance[0]:.4f}")
print(f"Expected Annual Volatility: {mvo_performance[1]:.4f}")
print(f"Sharpe Ratio: {mvo_performance[2]:.4f}")
print("\nOptimal Portfolio Weights:")
print(mvo_results)
```

## Performer Model Implementation

Now, let's implement the Performer Model for portfolio optimization:

```{python}
class PerformerAttention(nn.Module):
    """
    Linear attention mechanism used in the Performer model
    """
    def __init__(self, dim, num_heads=8, kernel_fn=nn.ReLU(), eps=1e-6):
        super().__init__()
        self.dim = dim
        self.num_heads = num_heads
        self.head_dim = dim // num_heads
        self.scale = self.head_dim ** -0.5
        self.kernel_fn = kernel_fn
        self.eps = eps
        
        # Linear projections for Q, K, V
        self.to_q = nn.Linear(dim, dim)
        self.to_k = nn.Linear(dim, dim)
        self.to_v = nn.Linear(dim, dim)
        self.to_out = nn.Linear(dim, dim)
        
    def forward(self, x):
        b, n, d = x.shape
        h = self.num_heads
        
        # Project inputs to queries, keys and values
        q = self.to_q(x).reshape(b, n, h, self.head_dim).transpose(1, 2)
        k = self.to_k(x).reshape(b, n, h, self.head_dim).transpose(1, 2)
        v = self.to_v(x).reshape(b, n, h, self.head_dim).transpose(1, 2)
        
        # Apply kernel feature map
        q = self.kernel_fn(q * self.scale)
        k = self.kernel_fn(k * self.scale)
        
        # Linear attention
        k_cumsum = k.sum(dim=2, keepdim=True)
        D_inv = 1. / (torch.einsum('bhnd,bhnd->bhn', q, k_cumsum) + self.eps)
        context = torch.einsum('bhnd,bhne->bhde', k, v)
        out = torch.einsum('bhnd,bhde,bhn->bhne', q, context, D_inv)
        
        # Merge heads and combine with output projection
        out = out.transpose(1, 2).reshape(b, n, d)
        return self.to_out(out)

class PerformerBlock(nn.Module):
    """
    Transformer block using Performer attention
    """
    def __init__(self, dim, num_heads=8, mlp_dim=256, dropout=0.1):
        super().__init__()
        self.norm1 = nn.LayerNorm(dim)
        self.attn = PerformerAttention(dim, num_heads=num_heads)
        self.norm2 = nn.LayerNorm(dim)
        self.mlp = nn.Sequential(
            nn.Linear(dim, mlp_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(mlp_dim, dim),
            nn.Dropout(dropout)
        )
        
    def forward(self, x):
        x = x + self.attn(self.norm1(x))
        x = x + self.mlp(self.norm2(x))
        return x

class PerformerForPortfolio(nn.Module):
    """
    Performer model for portfolio optimization
    """
    def __init__(self, num_assets, seq_length, dim=64, depth=4, heads=4, mlp_dim=128, dropout=0.1):
        super().__init__()
        self.num_assets = num_assets
        
        # Embedding layers
        self.asset_embedding = nn.Embedding(num_assets, dim)
        self.pos_embedding = nn.Parameter(torch.randn(1, seq_length, dim))
        self.input_projection = nn.Linear(1, dim)  # Project price/return to embedding dimension
        
        # Transformer blocks
        self.transformer_blocks = nn.ModuleList([
            PerformerBlock(dim, heads, mlp_dim, dropout) for _ in range(depth)
        ])
        
        # Output layers
        self.norm = nn.LayerNorm(dim)
        self.pool = nn.AdaptiveAvgPool1d(1)
        self.to_weights = nn.Sequential(
            nn.Linear(dim * num_assets, 128),
            nn.ReLU(),
            nn.Linear(128, num_assets),
            nn.Softmax(dim=1)  # Ensure weights sum to 1
        )
        
    def forward(self, x):
        b, n, t = x.shape  # batch, num_assets, time_steps
        
        # Create asset indices and expand to match batch size
        asset_indices = torch.arange(n, device=x.device)
        asset_indices = asset_indices.unsqueeze(0).expand(b, -1)
        
        # Get asset embeddings
        asset_emb = self.asset_embedding(asset_indices)  # (b, n, dim)
        
        # Process each asset's time series
        outputs = []
        for i in range(n):
            # Get time series for current asset
            asset_x = x[:, i, :].unsqueeze(-1)  # (b, t, 1)
            
            # Project to embedding dimension
            asset_x = self.input_projection(asset_x)  # (b, t, dim)
            
            # Add positional embeddings
            asset_x = asset_x + self.pos_embedding[:, :t, :]
            
            # Add asset embedding
            asset_x = asset_x + asset_emb[:, i, :].unsqueeze(1)
            
            # Pass through transformer blocks
            for block in self.transformer_blocks:
                asset_x = block(asset_x)
            
            # Apply normalization
            asset_x = self.norm(asset_x)
            
            # Pool across time dimension
            asset_x = asset_x.transpose(1, 2)  # (b, dim, t)
            asset_x = self.pool(asset_x).squeeze(-1)  # (b, dim)
            
            outputs.append(asset_x)
        
        # Concatenate outputs for all assets
        x = torch.cat(outputs, dim=1)  # (b, dim * num_assets)
        
        # Generate portfolio weights
        weights = self.to_weights(x)  # (b, num_assets)
        
        return weights

def train_performer_model(returns, seq_length=60, epochs=100, batch_size=32, learning_rate=0.001):
    """
    Train the Performer model for portfolio optimization
    """
    # Prepare the data
    num_assets = returns.shape[1]
    
    # Create sequences of returns
    sequences = []
    for i in range(len(returns) - seq_length):
        seq = returns.iloc[i:i+seq_length].values
        sequences.append(seq)
    
    sequences = np.array(sequences)
    
    # Split into training and validation sets
    train_data, val_data = train_test_split(sequences, test_size=0.2, random_state=42)
    
    # Convert to PyTorch tensors
    train_data = torch.tensor(train_data, dtype=torch.float32)
    val_data = torch.tensor(val_data, dtype=torch.float32)
    
    # Create data loaders
    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)
    val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)
    
    # Initialize the model
    model = PerformerForPortfolio(num_assets, seq_length)
    
    # Define loss function and optimizer
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    # Training loop
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        
        for batch in train_loader:
            optimizer.zero_grad()
            
            # Forward pass
            weights = model(batch.transpose(1, 2))
            
            # Calculate returns for the next day
            next_day_returns = torch.tensor(returns.iloc[seq_length:seq_length+len(batch)].values, dtype=torch.float32)
            
            # Calculate portfolio return
            portfolio_return = torch.sum(weights * next_day_returns, dim=1)
            
            # Calculate negative Sharpe ratio as loss
            mean_return = torch.mean(portfolio_return)
            std_return = torch.std(portfolio_return) + 1e-6  # Add small epsilon to avoid division by zero
            sharpe_ratio = mean_return / std_return
            loss = -sharpe_ratio
            
            # Backward pass and optimize
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        # Validation
        model.eval()
        val_loss = 0
        
        with torch.no_grad():
            for batch in val_loader:
                weights = model(batch.transpose(1, 2))
                next_day_returns = torch.tensor(returns.iloc[seq_length:seq_length+len(batch)].values, dtype=torch.float32)
                portfolio_return = torch.sum(weights * next_day_returns, dim=1)
                mean_return = torch.mean(portfolio_return)
                std_return = torch.std(portfolio_return) + 1e-6
                sharpe_ratio = mean_return / std_return
                val_loss += -sharpe_ratio.item()
        
        # Print progress
        if (epoch + 1) % 10 == 0:
            print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}')
    
    return model

# Train the Performer model
performer_model = train_performer_model(returns)

# Generate portfolio weights using the trained model
with torch.no_grad():
    # Use the most recent sequence of returns for prediction
    recent_returns = torch.tensor(returns.iloc[-60:].values, dtype=torch.float32).unsqueeze(0)
    performer_weights = performer_model(recent_returns.transpose(1, 2)).squeeze().numpy()

# Calculate performance metrics for the Performer model
performer_performance = calculate_portfolio_performance(performer_weights, returns)

# Display the results
performer_results = pd.DataFrame({
    'Asset': returns.columns,
    'Weight': performer_weights
})

print("Performer Model Results:")
print(f"Expected Annual Return: {performer_performance[0]:.4f}")
print(f"Expected Annual Volatility: {performer_performance[1]:.4f}")
print(f"Sharpe Ratio: {performer_performance[2]:.4f}")
print("\nOptimal Portfolio Weights:")
print(performer_results)
```

# Performance Comparison

Let's compare the performance of both approaches:

```{python}
# Create a DataFrame to compare the results
comparison = pd.DataFrame({
    'Asset': returns.columns,
    'MVO Weight': mvo_weights,
    'Performer Weight': performer_weights
})

# Calculate the difference in weights
comparison['Weight Difference'] = comparison['Performer Weight'] - comparison['MVO Weight']

# Display the comparison
print("Portfolio Weight Comparison:")
print(comparison)

# Create a summary of performance metrics
performance_summary = pd.DataFrame({
    'Metric': ['Expected Annual Return', 'Expected Annual Volatility', 'Sharpe Ratio'],
    'Mean-Variance Optimization': [mvo_performance[0], mvo_performance[1], mvo_performance[2]],
    'Performer Model': [performer_performance[0], performer_performance[1], performer_performance[2]],
    'Difference': [performer_performance[0] - mvo_performance[0], 
                  performer_performance[1] - mvo_performance[1], 
                  performer_performance[2] - mvo_performance[2]]
})

print("\nPerformance Metric Comparison:")
print(performance_summary)

# Visualize the weight allocation
plt.figure(figsize=(14, 8))

# Create a bar chart for weight comparison
x = np.arange(len(returns.columns))
width = 0.35

plt.bar(x - width/2, mvo_weights, width, label='MVO')
plt.bar(x + width/2, performer_weights, width, label='Performer')

plt.xlabel('Assets')
plt.ylabel('Weight')
plt.title('Portfolio Weight Allocation Comparison')
plt.xticks(x, returns.columns, rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

# Visualize the efficient frontier for MVO
def generate_efficient_frontier(returns, num_portfolios=1000):
    # Number of assets
    num_assets = len(returns.columns)
    
    # Generate random weights
    weights_record = np.zeros((num_portfolios, num_assets))
    returns_record = np.zeros(num_portfolios)
    volatility_record = np.zeros(num_portfolios)
    sharpe_record = np.zeros(num_portfolios)
    
    for i in range(num_portfolios):
        # Generate random weights
        weights = np.random.random(num_assets)
        weights = weights / np.sum(weights)
        weights_record[i] = weights
        
        # Calculate portfolio performance
        portfolio_return, portfolio_volatility, sharpe_ratio = calculate_portfolio_performance(weights, returns)
        
        # Record the results
        returns_record[i] = portfolio_return
        volatility_record[i] = portfolio_volatility
        sharpe_record[i] = sharpe_ratio
    
    return returns_record, volatility_record, sharpe_record, weights_record

# Generate the efficient frontier
returns_record, volatility_record, sharpe_record, weights_record = generate_efficient_frontier(returns)

# Plot the efficient frontier
plt.figure(figsize=(12, 8))
plt.scatter(volatility_record, returns_record, c=sharpe_record, cmap='viridis', marker='o', s=10, alpha=0.3)
plt.colorbar(label='Sharpe Ratio')

# Plot the MVO and Performer portfolios
plt.scatter(mvo_performance[1], mvo_performance[0], c='red', marker='*', s=300, label='MVO Portfolio')
plt.scatter(performer_performance[1], performer_performance[0], c='blue', marker='*', s=300, label='Performer Portfolio')

plt.title('Efficient Frontier')
plt.xlabel('Expected Volatility')
plt.ylabel('Expected Return')
plt.legend()
plt.grid(True)
plt.show()

# Backtest the portfolios
def backtest_portfolio(weights, returns, window=252):
    """
    Backtest a portfolio with fixed weights over a rolling window
    """
    # Calculate daily portfolio returns
    portfolio_returns = np.sum(returns * weights, axis=1)
    
    # Calculate cumulative returns
    cumulative_returns = (1 + portfolio_returns).cumprod()
    
    # Calculate rolling metrics
    rolling_returns = portfolio_returns.rolling(window=window).mean() * 252
    rolling_volatility = portfolio_returns.rolling(window=window).std() * np.sqrt(252)
    rolling_sharpe = rolling_returns / rolling_volatility
    
    return portfolio_returns, cumulative_returns, rolling_returns, rolling_volatility, rolling_sharpe

# Backtest both portfolios
mvo_portfolio_returns, mvo_cumulative_returns, mvo_rolling_returns, mvo_rolling_volatility, mvo_rolling_sharpe = backtest_portfolio(mvo_weights, returns)
performer_portfolio_returns, performer_cumulative_returns, performer_rolling_returns, performer_rolling_volatility, performer_rolling_sharpe = backtest_portfolio(performer_weights, returns)

# Plot cumulative returns
plt.figure(figsize=(14, 8))
plt.plot(returns.index, mvo_cumulative_returns, label='MVO Portfolio')
plt.plot(returns.index, performer_cumulative_returns, label='Performer Portfolio')
plt.title('Cumulative Portfolio Returns')
plt.xlabel('Date')
plt.ylabel('Cumulative Return')
plt.legend()
plt.grid(True)
plt.show()

# Plot rolling Sharpe ratio
plt.figure(figsize=(14, 8))
plt.plot(returns.index[252:], mvo_rolling_sharpe[252:], label='MVO Portfolio')
plt.plot(returns.index[252:], performer_rolling_sharpe[252:], label='Performer Portfolio')
plt.title('Rolling 1-Year Sharpe Ratio')
plt.xlabel('Date')
plt.ylabel('Sharpe Ratio')
plt.legend()
plt.grid(True)
plt.show()
```

# Analysis and Discussion

## Comparison of Weight Allocations

The weight allocations between the Mean-Variance Optimization (MVO) and the Performer Model show interesting differences. MVO tends to concentrate weights in assets with historically higher Sharpe ratios, while the Performer Model may distribute weights differently based on learned patterns in the time series data.

The key differences in weight allocation can be attributed to:

1. **Linear vs. Non-linear Relationships**: MVO assumes linear relationships between assets, while the Performer Model can capture non-linear dependencies through its attention mechanism.

2. **Historical vs. Learned Patterns**: MVO relies solely on historical means and covariances, while the Performer Model learns patterns from sequences of returns that may be predictive of future performance.

3. **Static vs. Dynamic**: MVO provides a static allocation based on the entire historical period, while the Performer Model can adapt to changing market conditions by focusing on more recent patterns.

## Performance Metrics Comparison

When comparing the performance metrics:

1. **Expected Return**: The Performer Model may achieve higher expected returns by identifying patterns that are not captured by simple historical averages.

2. **Volatility**: The Performer Model might achieve lower volatility by better understanding the complex relationships between assets and their changing correlations over time.

3. **Sharpe Ratio**: The overall risk-adjusted performance (Sharpe ratio) comparison shows whether the Performer Model's ability to capture complex patterns translates into better risk-adjusted returns.

## Strengths and Limitations

### Mean-Variance Optimization

**Strengths:**
- Well-established theoretical foundation
- Computationally efficient
- Easy to interpret and implement
- Works well in markets that follow assumptions of normal distributions

**Limitations:**
- Assumes returns follow a normal distribution
- Sensitive to estimation errors in expected returns
- Cannot capture non-linear relationships
- Static allocation that doesn't adapt to changing market conditions

### Performer Model

**Strengths:**
- Can capture complex non-linear relationships
- Learns from sequential patterns in the data
- Potentially adapts better to changing market conditions
- Linear computational complexity makes it efficient for large datasets

**Limitations:**
- Requires more data for training
- More complex to implement and interpret
- May overfit to historical patterns
- Requires careful hyperparameter tuning

# Conclusion

This study compared the traditional Mean-Variance Optimization approach with the modern Performer Model (Linear Attention Transformer) for portfolio optimization. The results demonstrate the potential advantages and limitations of both approaches.

The Performer Model shows promise in capturing complex patterns in financial time series data that may not be evident in simple statistical measures used by MVO. However, the effectiveness of the Performer Model depends on various factors, including the quality and quantity of training data, model architecture, and hyperparameter tuning.

For practical applications, a hybrid approach might be beneficial, combining the theoretical foundation of MVO with the pattern recognition capabilities of the Performer Model. This could provide a more robust portfolio optimization framework that leverages the strengths of both approaches.

Future research could explore:
1. Incorporating additional features beyond just returns
2. Testing on different asset classes and market conditions
3. Developing ensemble methods that combine multiple approaches
4. Exploring other variants of linear attention mechanisms

# References

1. Markowitz, H. (1952). Portfolio Selection. The Journal of Finance, 7(1), 77-91.
2. Choromanski, K., Likhosherstov, V., Dohan, D., Song, X., Gane, A., Sarlos, T., ... & Weller, A. (2020). Rethinking Attention with Performers. arXiv preprint arXiv:2009.14794.
3. Bodie, Z., Kane, A., & Marcus, A. J. (2014). Investments (10th ed.). McGraw-Hill Education.
4. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.
